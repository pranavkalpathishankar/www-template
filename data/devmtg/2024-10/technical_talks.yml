technical_talks:
  - title: "Modern Embedded Development with LLVM"
    speaker: "Petr Hosek"
    video_url: "https://youtu.be/5hHQi-Uj34I"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Hosek-ModernEmbeddedDevelopment-with-LLVM.pdf"
    description: |
      Modern day embedded development is anything but modern. I believe that we can change
      the way embedded development is done by using a modern toolchain based on LLVM and
      adopting practices that have become commonplace for C/C++ user-space software development.
      In this talk, I will cover our experience from migrating several internal and external
      baremetal projects to the Clang toolchain, the issues we encountered and the opportunities
      we discovered.

  - title: "What we learned from building Mojo’s optimization pipeline"
    speaker: "Weiwei Chen"
    video_url: "https://youtu.be/yuSBEXkjfEA"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Weiwei-What-We-Learned-Building-Mojo-OptimizationPipeline.pdf"
    description: |
      Mojo is a programming language for heterogenous compute built on top of MLIR and
      LLVM. Like many other programming languages and compiler systems built this way, the LLVM
      pipeline is often the bottleneck for compilation time. In this talk, we will share our
      strategies for wrestling with LLVM and leveraging MLIR passes in our pipeline design to
      significantly reduce compilation time without sacrificing generated code performance. As a
      result, we cut time spent in LLVM from 80% to 20% of overall Mojo compilation time.
  
  - title: "Floating Point in LLVM: the Good, the Bad, and the Absent"
    speaker: "Joshua Cranmer"
    video_url: "https://youtu.be/sSNAGFXNXYU"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Cranmer-FloatingPoint-in-LLVM.pdf"
    description: |
      This talk will cover the current state of semantics in floating-point for LLVM: the
      things that work, the things that don't work, and the things that are just plain missing
      entirely.

  - title: "Higher-Level Linker Scripts for Embedded Systems"
    speaker: "Daniel Thornburgh"
    video_url: "https://youtu.be/t-lvIFmggmA"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Thornburgh-Higher-LevelLinkerScripts-forEmbeddedSystems.pdf"
    description: |
      Embedded systems intrinsically place idiosyncratic constraints on the memory
      addresses of code and data. These constraints are typically met by explicitly placing
      sections using linker scripts. This talk explores these constraints and introduces section
      classes, a new LLD feature that provides a higher-level way to control placement. This
      largely removes the toil of updating linker scripts in response to changes to code/data
      sizes.

  
  - title: "Towards Useful Fast-Math"
    speaker: "Andy Kaylor"
    video_url: "https://youtu.be/3Uf_3Su1NEc"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Kaylor-Towards-Useful-Fast-Math.pdf"
    description: |
      Fast-math semantic modes provide a way to selectively relax the default rules for
      numeric consistency used by the compiler. Relaxing these rules can improve performance,
      but it can also introduce accuracy errors. This talk will describe a technique to track
      down the cause of such errors and introduce a proposal for new LLVM optimizer
      infrastructure to make the debugging process easier.


  - title: "LLVM libc math library - Current status and future directions"
    speaker: "Tue Ly"
    video_url: "https://youtu.be/-8zb8rHbvcQ"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Ly-LLVM-libc-math-library-CurrentStatus.pdf"
    description: |
      LLVM libc math library aim to be a correctly rounded, performant, and complete C23
      math library that supports various targets and use-cases. In this talk, we will go over
      some of the recent milestones and production usages of the LLVM libc math library, and our
      plans and directions for the near future.


  - title: "Exploiting MLIR Abstractions for Hardware Verification"
    speaker: "Bea Healy, Luisa Cicolini"
    video_url: "https://youtu.be/ga0VHhwmKMM"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Healy-Cicolini-ExploitingMLIR-Abstractions-for-HardwareVerification.pdf"
    description: |
      Hardware verification is a fundamental, yet often painful, step of hardware design.
      This talk will discuss how MLIR can accelerate this process through the CIRCT
      infrastructure, an MLIR hardware compiler containing dialects that describe hardware at
      both high and low levels of abstraction. We will describe how to generate models for
      verification from such high-level abstractions - specifically from the finite state
      machine (FSM) dialect - to check properties at higher levels and optimize the overall
      verification procedure.


  - title: "Advancing SPIR-V Backend Stability: Navigating GlobalISel Compromises"
    speaker: "Michal Paszkowski, Vyacheslav Levytskyy"
    video_url: "https://youtu.be/oLuTsD4mLXE"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Paszkowski-Levytskyy-AdvancingSPIR-V-BackendStability.pdf"
    description: |
      This presentation outlines the recent advancements and ongoing challenges in the
      development of the SPIR-V backend, which has become a crucial component for supporting
      OpenCL, SYCL/DPC++, and soon Vulkan inside LLVM. The talk highlights the inherent
      complexities of generating SPIR-V, a higher-level representation compared to LLVM IR,
      through conventional GlobalISel translation schema. Key issues such as the translation of
      opaque pointers, pointer and builtin type inference, and the integration of new SPIR-V
      extensions are discussed. The session will cover strategies for ensuring backward
      compatibility with older LLVM IR, maintaining [g]MIR correctness across passes, and
      verifying SPIR-V binaries through GitHub actions using existing LIT tests and external
      tools. Plans to further integrate SPIR-V into LLVM with a new frontend are also presented.


  - title: "New llvm-exegesis Support for RISC-V Vector Extension"
    speaker: "Min Hsu"
    video_url: "https://youtu.be/h2tDWoTWUnw"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Hsu-RVV-Exegesis.pdf"
    description: |
      llvm-exegesis has been instrumental in calibrating LLVM's scheduling models using
      hardware-collected metrics, such as instruction latency. In this talk, we'll unveil the
      first-ever llvm-exegesis support for RISC-V vector (RVV) instructions. We'll explore the
      challenges of scaling llvm-exegesis to accommodate the extensive range of RVV opcodes and
      configurations, and how we've significantly enhanced its efficiency for use in pre-silicon
      hardware development environments like FPGA. Our work not only advances RISC-V but also
      benefits the broader LLVM community by improving the quality of scheduling models with
      llvm-exegesis.

  - title: "Loop Vectorisation: a quantitative approach to identify/evaluate opportunities"
    speakers: "Sjoerd Meijer"
    video_url: "https://youtu.be/u7W3_xL_3NQ"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Meijer-Loop-Vectorisation.pdf"
    description: |
      In previous LLVM developer conferences, there have been several presentations and
      discussions on loop vectorisation, focusing on the progress of the VPlan infrastructure
      and vectorisation for specific back-ends. In this talk, we aim to take a different
      approach by identifying patterns and types of loops that the loop vectoriser cannot
      vectorise. Specifically, we want to: i) identify the deficiencies and missing features of
      the loop vectoriser, ii) group these deficiencies and find common root causes for missed
      vectorisation opportunities, and iii) develop a vectorisation plan to enhance code-
      generation quality based on these insights. Therefore, the contributions of this work and
      talk include: 1. A quantitative approach to find loop vectorisation opportunities and
      evaluate deficiencies, 2. A presentation of benchmark numbers for two loop-based
      benchmarks TSVC-2 and RAJAPerf, 3. A first analysis of loop vectoriser deficiencies and
      opportunities. 4. Thoughts on measuring and evaluating compiler changes with the LLVM
      test-suite. Although we concentrated on AArch64 platforms for our results, most of your
      findings are broadly applicable.


  - title: "Enhance SYCL offloading support to use the new offloading model"
    speaker: "Ravi Narayanaswamy"
    video_url: "https://youtu.be/4Qof7vtfhuk"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Narayanaswamy-EnhanceSYCL-offloading-support.pdf"
    description: |
      Driven by Intel, SYCL compiler is an LLVM-based project that implements support for
      the SYCL language. In our downstream implementation, We (Intel) have made several changes
      to the clang-linker-wrapper tool to support SYCL device code linking and wrapping. This
      talk includes discussion of key changes to clang-linker-wrapper tool to enable JIT/AOT
      compilation flow for SYCL offloading, addition of a new sycl-post-link library, SYCL
      specific options passed to clang-linker-wrapper, and use of existing mechanism for
      propagating SYCL specific metadata from the compiler to SYCL runtime library.


  - title: "The State of Pattern-Based IR Rewriting in MLIR"
    speaker: "Matthias Springer"
    video_url: "https://youtu.be/xIeihq2WZOU"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Springer-Pattern-Based-IR-Rewriting-in-MLIR.pdf"
    description: |
      Pattern-based IR rewriting through the greedy pattern rewriter and the dialect
      conversion framework is widely used and one of the core mechanisms of MLIR. This talk will
      touch upon the parts of their APIs that have evolved/changed over the last years. The main
      part of the talk is a set of best practices that programmers can follow when designing
      pattern-based rewrites. Finally, this talk will briefly touch upon a new, simpler dialect
      conversion driver (without pattern rollback and automatic materializations) that is
      currently in development.


  - title: "Vectorization in MLIR: Towards Scalable Vectors and Matrices (Part 2)"
    speakers: "Andrzej Warzyński"
    video_url: "https://youtu.be/gaSb4BRRcmM"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Warzynski-Vectorization-in-MLIR.pdf"
    description: |
      This presentation builds on the "Vectorization in MLIR" talk delivered at LLVM Dev
      Meeting 2023, delving deeper into the Linalg Vectorizer's capabilities within MLIR. The
      Linalg Vectorizer combines a simple tiling and basic-block vectorization approach with
      advanced concepts such as vector masking or support for scalable vectors. In this follow-
      up session, we will explore the implementation details of the Linalg Vectorizer, focusing
      on how it handles Linalg operations beyond linalg.matmul, which was covered in the
      previous talk. We'll also compare various vectorization pre-processing strategies—such
      as masking, peeling, and padding—and demonstrate how to effectively apply these
      strategies. Additionally, we will address the unique challenges posed by scalable vectors,
      including our approach to extending value-bounds analysis to accommodate these
      complexities. Specifically, we'll provide an update on the ongoing support for the
      Scalable Matrix Extension (SME), a CPU extension that enables 2D scalable vectors.

      
  - title: "Efficient Coroutine Implementation in MLIR"
    speaker: "Steffi Stumpos"
    video_url: "https://youtu.be/ILjuvj13EpQ"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Stumpos-EfficientCoroutineImplementatio-inMLIR.pdf"
    description: |
      Because of the growing need to offload compute to GPUs and other types of customized
      hardware, asynchronous programming has become a necessary feature of modern programming
      languages. In this talk we will share our experience in designing and implementing the
      asynchronous programming feature in Mojo, an MLIR based language. We will reflect on our
      poor experience trying to use LLVM’s coroutines and walk through how we mitigated the
      same deficiencies when rewriting the passes in MLIR.

  
  - title: "LLVM Premerge Testing: Current State and Next Steps"
    speaker: "Lucile Rose Nihlen"
    video_url: "https://youtu.be/CLczt-RJzAA"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Nihlen-LLVM-Premerge-Testing.pdf"
    description: |
      Presenting a detailed technical overview of the current LLVM Premerge
      Infrastructure, the challenges it is facing and their proposed solutions, and a roadmap
      for the future development of the system.


  - title: "Fine-grained compilation caching using llvm-cas"
    speaker: "Shubham Rastogi"
    video_url: "https://youtu.be/c629Cggdes4"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Rastogi-Fine-grained-compilation-caching-using-llvm-cas.pdf"
    description: |
      Last year, we demonstrated how debug information can be efficiently represented in
      fine-grained caching. Since then, we have used this technology to build a drop-in
      replacement for ccache. It is built into clang, and therefore supports advanced features
      necessary for real-world use, such as caching of Clang modules. Debug information can make
      up to 90% of an object file, therefore, efficiently handling it is paramount for the size
      of a build cache, and its replay speed. This year, we further improved the size of debug
      information by redesigning the CAS schema, and applying compression. We also made
      improvements to the debug info decoder to maximize replay performance.


  - title: "Release Engineering Strategies: How LLVM and GCC Navigate Development and Maintenance"
    speaker: "Tom Stellard, David Edelsohn"
    video_url: "https://youtu.be/HwrQyOQBIpQ"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Edelsohn-GCC-and-LLVMDevelopment-and-Maintenance.pdf"
    description: |
      LLVM and GCC have evolved very different policies for release engineering
      (development cycle, scheduling, type of maintenance, duration of maintenance) that impacts
      the manner in which it is consumed and deployed by individual users, packagers (Linux
      distributions and product-versions of the compilers), and downstream projects. This
      session explores the differing approaches and if either compiler should consider changes
      in its policies to better address the needs of its user community or to make the
      development and release engineering process more efficient. The session will describe the
      release engineering process of the two compiler ecosystems followed by a conversation
      among the attendees about potential paths forward.


  - title: "Two Compilers, One Language, No Specification"
    speaker: "Chris Bieneman"
    video_url: "https://youtu.be/sVq5khCXkbw"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Bieneman-Two-Compilers-One-Language-NoSpecification.pdf"
    description: |
      The High Level Shader Language (HLSL) is a popular cross-platform programming
      language for GPUs focused on realtime graphics applications. Through its over 20 year life
      HLSL has had two reference compilers, but no specification. As HLSL support in Clang
      progresses, the implementers are working through challenges caused by the lack of a
      specification and the language inconsistencies between the reference implementations.

  - title: "Making upstream MLIR more friendly to programming languages: current upstream limitations,
            the ptr dialect, and the road ahead"
    speakers: "Mehdi Amini, Fabian Mora Cordero"
    video_url: "https://youtu.be/Bt__BDQivxo"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Amini-Cordero-MakingUpstreamMLIRMoreFriendly.pdf"
    description: |
      In this talk, we discuss the existing limitations of upstream MLIR for representing
      generic programming languages and propose solutions to address some of these issues. As
      part of our proposed solutions, we will discuss the potential modularization of the LLVM
      dialect. We also present the status of the recently upstreamed ptr dialect as a first step
      in the modularization of LLVM and the lessons learned from this ongoing upstreaming
      process. Finally, we discuss the road ahead for making MLIR more attractive for compiler
      developers for programming languages, like finally standardizing the C/C++ calling
      convention on MLIR.


  - title: "Hand-In-Hand: LLVM-libc and libc++ code sharing."
    speaker: "Michael Jones, Christopher Di Bella"
    video_url: "https://youtu.be/VAEO86YtTHA"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Jones-DiBella-hand-in-hand.pdf"
    description: |
      Have you ever wondered how libc++ implements functions that are similar to libc? For
      example, consider std::from_chars(float) and strtof. They both take a string and output a
      float, but from_chars also takes an end pointer and a format argument. They operate
      similarly behind the scenes. Their interfaces mean that from_chars can’t easily be
      implemented in terms of strtof. This talk will explain Project Hand-In-Hand, an LLVM-libc
      and libc++ collaboration to share the internal code for very similar functions that have
      incompatible interfaces.

  - title: "Challenges in Using LLVM as a Quantum Intermediate Representation"
    speaker: "Andrew Litteken"
    video_url: "https://youtu.be/lzl-qdswIgU"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Litteken-Challenges-Using-LLVM-as-a-QuantumIntermediate-Representation.pdf"
    description: |
      The most efficient programming and compilation paradigms for quantum computing are
      still being explored as new applications and architectures are developed. This talk lays
      out several challenges of performing quantum compilation, and how the Intel Quantum
      Compiler meets the requirements of quantum computation by using the LLVM infrastructure.
      Additionally, we will discuss how the Intel Quantum Compiler makes the quantum
      intermediate representation more approachable to users who are not familiar with compiler
      infrastructure including the Function Language Extension for Quantum (FLEQ) and Quantum
      Circuit Object framework.


  - title: "(Offload) ASAN via Software Managed Virtual Memory"
    speaker: "Johannes Doerfert"
    video_url: "https://youtu.be/B60jp4khrvc"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Doerfert-Offload-ASAN.pdf"
    description: |
      We present LLVM/Offload Sanitizer, an address sanitizer (ASAN) designed for GPUs. In
      contrast to the classic CPU ASAN, the offload sanitizer will avoids high memory overhead,
      and even memory traffic, via software managed virtual memory. Allocations result in
      "virtual pointers" that are checked and translated prior to accesses but without buffer
      zones and, in case of shared and local GPU memory, even without additional memory traffic.
      Our performance results show huge advantages against the classic CPU design ported to the
      GPU, however, we will details various pitfalls that make efficient sanitization of GPU
      code especially hard. Finally, we will show some initial comparison of this design against
      classic ASAN on the CPU.


  - title: "A C++ Toolchain for Your GPU"
    speakers: "Joseph Huber"
    video_url: "https://youtu.be/4TxGWis1mws"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Huber-A-CPlusPlus-Toolchain-for-Your-GPU.pdf"
    description: |
      This project seeks to treat the GPU as a standard hosted target by porting the LLVM
      C library, compiler runtime, and C++ runtime all to run on the GPU. We show how LLVM/Clang
      can be used to compile regular, freestanding C++ to target the GPU as well as show how to
      use this to create GPU libraries that can be stacked upon eachother.
  
  - title: "When unsafe code is slow - Automatic Differentiation in Rust"
    speakers: "Manuel Drehwald"
    video_url: "https://youtu.be/xEcoNuzhfBI"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Drehwald-AutomaticDifferentiation-in-Rust.pdf"
    description: |
      Automatic Differentiation was accepted as an experimental Rust feature for HPC, ML,
      and Scientific Computing applications. We present Rust-Enzyme, an LLVM-based autodiff tool
      and show that differentiating idiomatic Rust can lead to significantly better performance
      than differentiating similar C++ code. We will discuss rustc, LLVM, JAX, Enzyme and C++
      limitations to explain benchmark differences and prove that old performance assumptions
      for libraries and languages won't hold when compiler-based automatic differentiation is
      applied.

  
  - title: "A new constant expression interpreter for Clang"
    speakers: "Timm Baeder"
    video_url: "https://youtu.be/eMT1dBlaggQ"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Baeder-A-new-constant-expression-interpreter-for-Clang.pdf"
    description: |
      In this talk, we will look at the development status of the new bytecode interpreter
      for constant expressions in Clang, implementation challenges as well as future development
      plans.

  
  - title: "Generic implementation strategies in Carbon and Clang"
    speakers: "Richard Smith"
    video_url: "https://youtu.be/j0BL52NdjAU"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Smith-Generic-implementation-strategies-in-Carbon-and-Clang.pdf"
    description: |
      A dive into the generics implementation in the Carbon toolchain and the templates
      implementation in Clang. This talk will contrast the approaches taken and discuss some
      benefits of each direction.

  - title: "JSIR - Adversarial JavaScript Detection With MLIR"
    speakers: "Zhixun Tan"
    video_url: "https://youtu.be/SY1ft5EXI3I"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Tan-JSIR.pdf"
    description: |
      Adversarial JavaScript is everywhere - web pages, mobile apps, browser extensions…
      you name it! To better support the detection of adversarial JavaScript, Google is using
      MLIR to develop JSIR, a JavaScript intermediate representation. JSIR needs to support
      dataflow analysis to extract suspicious signals from the code, source-to-source
      transformations to simplify obfuscated code, and even binary-to-source transformations for
      bytecode decompilation. In this talk, we describe several IR design choices we made due to
      the unique requirements of adversarial code analysis.


  - title: "Clang Modules at Scale"
    speakers: "Michael Spencer, Ian Anderson"
    video_url: "https://youtu.be/tcB1vXc4L8M"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Anderson-Spencer-ClangModules-at-Scale.pdf"
    description: |
      This presentation shares some of the things we've learned in the more than 10 years
      of deploying Clang modules in the SDKs. We explain what what a modular header actually is,
      what it takes to build thousands of modules, and the issues you may encounter when using
      Clang modules at scale.

  - title: "Shardy: An MLIR-based Tensor Partitioning System for All Dialects"
    speakers: "Bart Chrzaszcz, Zixuan Jiang"
    video_url: "https://youtu.be/po-Cxq2Acig"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Chrzaszcz-Jiang-Shardy.pdf"
    description: |
      Generative AI models are so large that the tensor programs they are represented as
      are required to be chunked (partitioned) into programs on thousands of hardware
      accelerators. Within Google DeepMind these models are being partitioned across TPU super
      clusters of over 4096 devices. In this presentation, we present a new MLIR tensor
      propagation system we have been developing and deploying to train these large AI models.
      We’ve defined our own dialect that expresses tensor shardings and compiler
      transformation rules as MLIR attributes. It is MLIR dialect agnostic, and has improved
      debugging capabilities and more configurability to the propagation algorithm over past
      systems.

  
  - title: "Swift Explicitly-Built Modules"
    speakers: "Artem Chikin"
    video_url: "https://youtu.be/DEjbcVRfSKA"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Chikin-Swift-Explicitly-Built-Modules.pdf"
    description: |
      Swift relies on modules exclusively for units of code distribution and library
      interface. Swift’s interoperability with C, ObjectiveC, and C++ leads to a heavy use of
      the concept of modules in the C family of languages. Building on top of Clang & LLVM
      infrastructure for dependency scanning, Swift is undergoing a transition to an Explicitly-
      Built Modules compilation model where all dependencies are discovered upfront, pre-built,
      and are specified as explicit inputs to compilation. This talk will describe this
      approach, its benefits compared to the prior Implicit Module Loading model, lessons
      learned along the way, and the extensive use of Clang infrastructure to support Swift’s
      interoperability with modules in the C family of languages.


  - title: "Simplifying GPU Programming with Parametric Tile-Level Tensors In Mojo"
    speakers: "Ahmed Taei"
    video_url: "https://youtu.be/sOZWhPVvRdw"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Taei-Simplifying-GPU-Programming-with-Parametric-Tile-Level-Tensors-In-Mojo.pdf"
    description: |
      Today’s AI GPU workloads are dominated by operations such as matrix multiplication
      (matmul) and flash-attention, with state-of-the-art implementations designed to leverage
      the compute and memory hierarchy of modern GPUs at a tile-level granularity. Expressing
      these algorithms at this level, rather than using the low-level SIMT (Single Instruction,
      Multiple Threads) model, presents a significant challenge for kernel developers. In this
      talk, we will demonstrate how Mojo, a systems programming language built on MLIR,
      addresses this challenge through its powerful metaprogramming capabilities. Mojo enables
      the creation of simple yet powerful composable abstractions for parametric Tensor types,
      which can be tiled, distributed across the compute hierarchy, and vectorized.
      Additionally, the language provides GPU library authors with direct access to MLIR, making
      it easier for library authors to specialize high-level library operations for specific
      hardware targets, which facilitates the efficient development of state-of-the-art GPU
      kernels that outperform vendor libraries like cuBLAS.


  - title: "lean-mlir: A Workbench for formally verifying Peephole Optimizations for MLIR"
    speakers: "Alex Keizer, Siddharth Bhat"
    video_url: "https://youtu.be/4lh2NnLOxvQ"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Keizer-Bhat-lean-mlir.pdf"
    description: |
      We aim to combine the convenience of automation with the versatility of ITPs for
      verifying peephole rewrites across domain-specific IRs. Our tool (lean-mlir) built in the
      Lean proof assistant provides: (a) a user-friendly frontend, (b) scaffolding for defining
      and verifying peephole rewrites, and (c) proof automation for semi-automatically verifying
      common compiler IR patterns. In this talk, we will showcase our work in bringing an Alive-
      style workflow for peephole optimizations over an LLVM style IR in Lean. We will sketch
      out our future vision, with the goal of making formal verification a core part of the day-
      to-day compiler development workflow. We hope to engage the community into providing
      formal semantics for many of the more complex IRs in the MLIR ecosystem.


  - title: "Improving optimized code line table quality"
    speakers: "Orlando Cazalet-Hyams"
    video_url: "https://youtu.be/yj1EUzXVP1I"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Cazalet-Hyams-Improving-optimized-code-line-table-quality.pdf"
    description: |
      Debug line tables are a key part of many development processes, including SPGO,
      debugging, and crash dumps. When optimising code, LLVM struggles to maintain attribution
      of source-lines to instructions, or to make debugger-stepping behaviours similar to the
      debugging unoptimised code. We propose techniques to solve to these issues, and present
      our evaluation of how they perform.

  - title: "Implementing Linear / Non-destructible Types in Vale and Mojo"
    speakers: "Evan Ovadia"
    video_url: "https://youtu.be/IpuvQUVB8Cg"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Ovadia-LinearTypes-in-Vale-and-Mojo.pdf"
    description: |
      Linear types are the secret ingredient to ensuring "liveness": the guarantee that
      desired future operations will happen. With them, you can solve caching problems,
      guarantee the completion of futures, ensure messages to other threads are actually
      handled, and a lot of other unexpected benefits. We'll talk about what they are, how
      they're implemented in Vale, and how we can add them to the Mojo compiler to bring them
      into the mainstream.


  - title: "Adding Pointer Authentication ABI support for your ELF platform"
    speakers: "Anton Korobeynikov"
    video_url: "https://youtu.be/bytWm7BzJVE"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Korobeynikov-Adding-Pointer-Authentication-ABI-support.pdf"
    description: |
      Recently the majority of the patches required to support Pointer Authentication
      C/C++ ABI were ported from downstream implementation for arm64e platform and were
      submitted & integrated into LLVM mainline (and are included in the LLVM 19 release). We
      have complemented them with the required changes to enable pointer authentication on ELF
      platforms. In this talk we will present the current status of Pointer Authentication ABI
      for ELF platforms, its components, their specifics and the different choices that platform
      should make to deploy the said ABI. We will also discuss the required changes that
      platforms must undertake beyond the compiler toolchain and present some proofs of concept
      implementations based on the Musl library.


  - title: "Manifesto for faster build times"
    speakers: "Alexandre Ganea, Francisco Cabrita"
    video_url: "https://youtu.be/1Gi9nPVUZro"
    slides_url: "N/A"
    description: |
      Build times and developer iteration are important to you? Wait no more! This talk
      will discuss a user's point of view and then sketch out a plan for reducing the
      compilation times of large C++ projects. We will discuss how the LLVM fundations could be
      incrementaly changed to achieve this goal, and how collaboration could be shaped.

  - title: "Mitigating use-after-free security vulnerabilities in C and C++ with language support for type-isolating allocators"
    speakers: "Oliver Hunt"
    video_url: "https://youtu.be/GGGaiGpm5BY"
    slides_url: "https://llvm.org/devmtg/2024-10/slides/techtalk/Hunt-Mitigating-use-after-free-security-vulnerabilities.pdf"
    description: |
      Type based segregation of heap allocations has long been acknowledged as an
      effective mechanism to mitigate memory safety vulnerabilities in real world C and C++. A
      core problem in the general deployment of segregating allocators is the lack of language
      level support, such that all adoption must be manual, and existing code must be manually
      updated to adopt new allocator APIs. In this talk we will be presenting our work to
      address this problem through our proposed typed memory operations extension for Clang, and
      our proposal for typed allocation support in the C++ language specification.